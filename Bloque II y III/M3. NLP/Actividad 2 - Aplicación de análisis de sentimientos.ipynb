{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2: Aplicación de análisis de sentimientos\n",
    "\n",
    "> Alfonso Pineda Cedillo | A01660394\n",
    "\n",
    "**Fecha de entrega:** 27 de Octubre de 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones\n",
    "\n",
    " **Parte 1:**\n",
    " \n",
    " - Seleccione un corpus a trabajar.\n",
    "    - Puede ser el corpus utilizado en los ejercicios anteriores.\n",
    "    - Un dataset de tweets podría ser un buen ejemplo.\n",
    "    - Dataset minado de alguna red social como todos los comentarios de un post de una figura pública.\n",
    "\n",
    " - Aplicar un modelo pre entrenado del “sentiment analisis” y analizar reacciones de un post.\n",
    "\n",
    "**Parte 2:**\n",
    "\n",
    " Del corpus utilizado en la parte 1, realiza lo siguiente:\n",
    "\n",
    " - Separe las oraciones después de cada punto.\n",
    "\n",
    " - Contabilice el número total de oraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "\n",
    "Como primer paso, se importan las librerías necesarias para el desarrollo de la actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import re\n",
    "import urllib.request\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, realizamos la carga de nuestro dataset, el cual contiene 1,600,000 tweets extraídos usando el API de Twitter. El dataset contiene 6 columnas, de las cuales solo nos interesa la columna de `text` y la columna `target`, la cual indica si el tweet es positivo, negativo o neutral. Para este proceso, ocupamos la librería `pandas` y la función `read_csv` para leer el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos desde el archivo CSV\n",
    "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "dataset = pd.read_csv('datasets/tweets.csv', encoding='ISO-8859-1', names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, realizamos un pequeño análisis exploratorio de los datos, para ver el formato general de la base de datos y ver si hay datos faltantes. Para esto, ocupamos la función `head()` para ver los primeros 5 registros de la base de datos, y la función `info()` para ver el tipo de dato de cada columna y si hay datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   ids     1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el modelo pre-entrenado, ocupamos únicamente la columna `text`, la cual contiene el contenido del tweet. Para esto, almacenamos los datos de la columna en una variable llamada `data` y posteriormente, observamos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...       0\n",
       "1        is upset that he can't update his Facebook by ...       0\n",
       "2        @Kenichan I dived many times for the ball. Man...       0\n",
       "3          my whole body feels itchy and like its on fire        0\n",
       "4        @nationwideclass no, it's not behaving at all....       0\n",
       "...                                                    ...     ...\n",
       "1599995  Just woke up. Having no school is the best fee...       4\n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...       4\n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...       4\n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...       4\n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...       4\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[['text', 'target']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos la carga del modelo pre-entrenado y del tokenizador. Para esto, se define la ruta al modelo pre-entrenado que se desea utilizar. El modelo en cuestión se llama \"cardiffnlp/twitter-roberta-base-sentiment\". Este modelo ha sido pre-entrenado en datos relacionados con Twitter y está diseñado para realizar tareas de análisis de sentimiento en texto de Twitter.\n",
    "\n",
    " Asimismo, ocupamos la función `AutoTokenizer.from_pretrained` para cargar el tokenizador. El tokenizador es una parte esencial del procesamiento de texto, ya que se encarga de dividir el texto en unidades más pequeñas, como palabras o subpalabras, que son comprensibles para el modelo. En este caso, el tokenizador se adapta al modelo pre-entrenado y está diseñado específicamente para procesar texto de Twitter.\n",
    "\n",
    "Luego, se carga la configuración del modelo utilizando la función AutoConfig.from_pretrained(MODEL). La configuración del modelo incluye detalles sobre la arquitectura y las configuraciones específicas del modelo, como el número de capas, el tamaño del embedding, entre otros. Esta información es esencial para asegurarse de que el modelo se utilice de manera adecuada.\n",
    "\n",
    "Finalmente, se carga el modelo en sí utilizando la función TFAutoModelForSequenceClassification.from_pretrained(MODEL). El modelo pre-entrenado es una red neuronal profunda que ha sido entrenada en una gran cantidad de datos para realizar tareas de clasificación de secuencias, en este caso, análisis de sentimiento. El modelo ya ha aprendido patrones y características relevantes en el lenguaje natural a partir de los datos de Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo preentrenado y el tokenizador\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, se define una función denominada `preprocess` con el propósito de realizar el preprocesamiento de texto. Este procedimiento es fundamental en el procesamiento de lenguaje natural y se utiliza para limpiar y estandarizar el texto de entrada antes de realizar análisis más avanzados. La función se encarga de aplicar dos principales transformaciones al texto ingresado como argumento.\n",
    "\n",
    "En primer lugar, la función efectúa la eliminación de menciones de usuario en el texto. Esto se logra mediante el uso de expresiones regulares (regex). Las menciones de usuario en plataformas de redes sociales como Twitter suelen comenzar con el símbolo '@', seguido de un nombre de usuario que puede consistir en letras, números y guiones bajos. La función `re.sub` se utiliza para reemplazar todas las menciones de usuario en el texto original por la etiqueta '@user'. Esta acción es relevante ya que permite eliminar información específica de usuarios en el texto, lo que puede ser útil en tareas de análisis de sentimiento y procesamiento de texto en general.\n",
    "\n",
    "En segundo lugar, la función lleva a cabo la eliminación de enlaces (URLs) del texto de entrada. Las URLs suelen comenzar con \"http\" o \"https\" y pueden ser seguidas por caracteres diversos que representan una dirección web. Al igual que en el caso de las menciones de usuario, la función `re.sub` se utiliza para reemplazar todas las URLs en el texto original por la etiqueta 'http'. Esta acción es significativa porque permite suprimir enlaces web que no suelen contener información relevante para el análisis de sentimiento o procesamiento de texto en sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preprocesar el texto\n",
    "def preprocess(text):\n",
    "    # Eliminar menciones de usuario\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '@user', text)\n",
    "    # Eliminar enlaces\n",
    "    text = re.sub(r'http\\S+', 'http', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definimos una función llamada `analyze_sentiment`, que se utiliza para realizar el análisis de sentimiento en un tweet dado. Esta función realiza una serie de pasos para evaluar la polaridad del sentimiento (positivo, negativo o neutral) en el texto del tweet.\n",
    "\n",
    "En primer lugar, el código invoca la función antes mencionada, llamada `preprocess(text)`. Después del preprocesamiento, se codifica el texto limpio utilizando un tokenizador previamente cargado. El texto procesado se pasa al modelo pre-entrenado para realizar la predicción de sentimiento. El modelo genera una puntuación (score) para cada clase de sentimiento (positivo, negativo y neutral).\n",
    "\n",
    "Para determinar la etiqueta de sentimiento correspondiente, el código realiza una serie de pasos adicionales. Primero, se normaliza las puntuaciones mediante una función softmax, lo que produce una distribución de probabilidad sobre las clases de sentimiento. Luego, las etiquetas se recuperan a partir de un archivo de mapeo (mapping) ubicado en una URL específica. Las etiquetas representan las clases de sentimiento a las que se asocian las puntuaciones.\n",
    "\n",
    "Finalmente, se ordenan las puntuaciones en orden descendente, lo que permite identificar la etiqueta de sentimiento más probable. Las etiquetas y las puntuaciones se imprimen en la consola, lo que brinda información sobre el sentimiento estimado del tweet, junto con la confianza asociada a esa estimación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='tf')\n",
    "    output = model(encoded_input)\n",
    "    scores = output[0][0].numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "\n",
    "    # Definir el mapeo de etiquetas\n",
    "    mapping = {\n",
    "        0: 'negative',\n",
    "        1: 'neutral',\n",
    "        2: 'positive'\n",
    "    }\n",
    "\n",
    "    sentiment_result = {}\n",
    "    for i in range(scores.shape[0]):\n",
    "        label_id = ranking[i]  # Obtener la etiqueta como entero\n",
    "        label = mapping[label_id]  # Obtener el nombre de la etiqueta\n",
    "        score = scores[ranking[i]]\n",
    "        sentiment_result[label] = np.round(float(score), 4)\n",
    "        # print(f\"{i+1}) {label} {np.round(float(score), 4)}\")\n",
    "\n",
    "    return sentiment_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, obtenemos 10 tweets aleatorios del dataset previamente importado y aplicamos la función `analyze_sentiment` a cada uno de ellos. Esto nos permite observar el funcionamiento del modelo pre-entrenado en la práctica y ver cómo se comporta en diferentes casos de uso.\n",
    "\n",
    "El dataset escogido para probar el modelo es diferente que el utilizado para su entrenamiento. Esto due hecho a propósito para ver cómo se comporta el modelo en un dataset que no ha visto antes. Los resultados obtenidos se imprimen primero mostrando el tweet analizado y posteriormente, la etiqueta de sentimiento y la confianza asociada a esa estimación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @ChrisBaragar Me too \n",
      "1) neutral 0.7331\n",
      "2) positive 0.1897\n",
      "3) negative 0.0772\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: the &quot;history of Art &quot; is so,well BORING! and long, so long \n",
      "1) neutral 0.4315\n",
      "2) positive 0.3709\n",
      "3) negative 0.1976\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @Tymethief Glad to hear it  bummer on the electric though.\n",
      "1) positive 0.7591\n",
      "2) neutral 0.2077\n",
      "3) negative 0.0331\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @wynlim I looked at my network settings and I don't see anythig there... \n",
      "1) neutral 0.4985\n",
      "2) negative 0.4697\n",
      "3) positive 0.0319\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: Ahhhhhh! My backyard. \n",
      "1) positive 0.6056\n",
      "2) neutral 0.3381\n",
      "3) negative 0.0563\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @giblahoj so don't wake up \n",
      "1) neutral 0.6138\n",
      "2) negative 0.3334\n",
      "3) positive 0.0528\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: My sweety has appeared  Almost...\n",
      "1) positive 0.5533\n",
      "2) neutral 0.437\n",
      "3) negative 0.0097\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @barbedwyer ha ha!  So hav u bn to Northern Ireland? Oh thank you re: photo of my mum! My father is v lucky! xxx\n",
      "1) positive 0.9616\n",
      "2) neutral 0.0356\n",
      "3) negative 0.0028\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: I really don't want to give up the fun that was this weekend \n",
      "1) positive 0.5409\n",
      "2) neutral 0.2878\n",
      "3) negative 0.1713\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @Tamara_RJ nah i had the regular ones   but they were still great, LOL\n",
      "1) positive 0.9453\n",
      "2) neutral 0.0498\n",
      "3) negative 0.005\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Elegir 10 tweets aleatorios\n",
    "random_tweets = data.sample(10)\n",
    "\n",
    "# Aplicar el análisis de sentimiento a los 10 tweets aleatorios\n",
    "for index, row in random_tweets.iterrows():\n",
    "    text = row['text']\n",
    "    print(f\"Tweet: {text}\")\n",
    "    analyze_sentiment(text)\n",
    "    print(\"\\n------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la longitud del dataset original (1,600,000 tweets), se decidió utilizar una muestra de 100,000 tweets para realizar el análisis de sentimiento. Para esto, se utilizó la función `groupby` para agrupar los tweets por su etiqueta de sentimiento y posteriormente, se utilizó la función `sample` para obtener una muestra de 50,000 tweets por cada etiqueta de sentimiento. Esto nos permite obtener una muestra equilibrada de tweets positivos y negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    50000\n",
      "4    50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar la cantidad de registros para cada categoría de 'target'\n",
    "target_counts = data['target'].value_counts()\n",
    "\n",
    "# Definir la cantidad de registros que se desean muestrear por categoría\n",
    "sample_size_per_category = 50000 \n",
    "\n",
    "# Realizar el muestreo equilibrado\n",
    "sampled_data = data.groupby('target', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size_per_category)))\n",
    "\n",
    "# Restablecer el índice del dataset resultante\n",
    "sampled_data = sampled_data.reset_index(drop=True)\n",
    "\n",
    "# Verificar que el muestreo sea equilibrado\n",
    "sampled_target_counts = sampled_data['target'].value_counts()\n",
    "print(sampled_target_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el modelo de análisis de sentimiento a todo el dataset y almacenamos los resultados obtenidos en 3 nuevas columnas llamadas 'positive', 'negative' y 'neutral'. Estas columnas contienen la probabilidad de que el tweet sea positivo, negativo o neutral, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el análisis de sentimiento a todo el dataset\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "for index, row in sampled_data.iterrows():\n",
    "    text = row['text']\n",
    "    sentiment_result = analyze_sentiment(text)\n",
    "    positive_scores.append(sentiment_result.get('positive', 0))\n",
    "    negative_scores.append(sentiment_result.get('negative', 0))\n",
    "    neutral_scores.append(sentiment_result.get('neutral', 0))\n",
    "\n",
    "# Agregar las columnas al dataset\n",
    "sampled_data['Positive'] = positive_scores\n",
    "sampled_data['Negative'] = negative_scores\n",
    "sampled_data['Neutral'] = neutral_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy fathers day to all the dads out there......</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG noooo leah  u put that pic of us singing '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>0.4952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Bliezy Why don't you like Holland? I'm sure i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3744</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.3524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss my honey..  http://myloc.me/4zQb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.4403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Am sending good thoughts to my friend Carmi. H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>@jonwaldock i hope it goes well  have fun!</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>@katelyntarver my star  can't wait to see u</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>long long day. movies compressing itself in th...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1911</td>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Back door. Good idea</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>@chrisjsimon ah alrite. hehe well feast your e...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.1083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  Positive  \\\n",
       "0      happy fathers day to all the dads out there......       0    0.9435   \n",
       "1      OMG noooo leah  u put that pic of us singing '...       0    0.0850   \n",
       "2      @Bliezy Why don't you like Holland? I'm sure i...       0    0.3744   \n",
       "3                  Miss my honey..  http://myloc.me/4zQb       0    0.0938   \n",
       "4      Am sending good thoughts to my friend Carmi. H...       0    0.7920   \n",
       "...                                                  ...     ...       ...   \n",
       "99995         @jonwaldock i hope it goes well  have fun!       4    0.9850   \n",
       "99996        @katelyntarver my star  can't wait to see u       4    0.9799   \n",
       "99997  long long day. movies compressing itself in th...       4    0.1911   \n",
       "99998                              Back door. Good idea        4    0.8212   \n",
       "99999  @chrisjsimon ah alrite. hehe well feast your e...       4    0.8873   \n",
       "\n",
       "       Negative  Neutral  \n",
       "0        0.0102   0.0462  \n",
       "1        0.4198   0.4952  \n",
       "2        0.2732   0.3524  \n",
       "3        0.4659   0.4403  \n",
       "4        0.0211   0.1869  \n",
       "...         ...      ...  \n",
       "99995    0.0016   0.0134  \n",
       "99996    0.0016   0.0185  \n",
       "99997    0.2203   0.5886  \n",
       "99998    0.0125   0.1663  \n",
       "99999    0.0044   0.1083  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los 5 tweets con mayor probabilidad de ser positivos, imprimiendo el texto del tweet y sus probabilidades de ser positivo. Comprobamos que los tweets con mayor probabilidad de ser positivos, efectivamente lo sean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "== Top 5 tweets más positivos ==\n",
      "================================\n",
      "\n",
      "Tweet: laying in bed, smiling the biggest smile. It's beautiful out and last night was so fun &lt;3  Happy Mothers Day! \n",
      "Positive Score: 0.9942\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @itschristablack i love reading your tweets. they make me happy and can't wait to see you guys aug 25 in nashville  be blessed today.\n",
      "Positive Score: 0.9941\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @Jonasbrothers congrats once again. haha. i'm lovin' it.  you guys are the best! &lt;3 come to singapore pleeeease.\n",
      "Positive Score: 0.994\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: Nice date night with my hubby, @charlienesdahl.  Celebrated good test result.  Love him so much!  \n",
      "Positive Score: 0.994\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @ kirstenamber Me n kirst are being the greatest big sisters ever today..... yay so excited its gonna be a fabulous day!! \n",
      "Positive Score: 0.994\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_positive = sampled_data.nlargest(5, 'Positive')\n",
    "\n",
    "# Mostrar los 5 tweets más positivos\n",
    "print(\"================================\")\n",
    "print(\"== Top 5 tweets más positivos ==\")\n",
    "print(\"================================\\n\")\n",
    "for index, row in top_positive.iterrows():\n",
    "    text = row['text']\n",
    "    positive_score = row['Positive']\n",
    "    print(f\"Tweet: {text}\")\n",
    "    print(f\"Positive Score: {positive_score}\")\n",
    "    print(\"\\n------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los 5 tweets con mayor probabilidad de ser negativos, imprimiendo el texto del tweet y sus probabilidades de ser negativo. Comprobamos que los tweets con mayor probabilidad de ser negativos, efectivamente lo sean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "== Top 5 tweets más negativos ==\n",
      "================================\n",
      "\n",
      "Tweet: My eyes have been hurting ridiculously for the past few days and I hate it. What have I done wrong to deserve this?! \n",
      "Negative Score: 0.985\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: i hate it that i've had this stupid cough for THREE weeks!! leave me alone!! \n",
      "Negative Score: 0.9849\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: I HATE LIVING IN TAMPA! I'm really lonely and extremely bored!! \n",
      "Negative Score: 0.9846\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: I HATE JETLAG!!! its 2 pm but why do i feel like its night time already?  i miss you canada\n",
      "Negative Score: 0.984\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: FUCK MY LIFE  uggggh! SO pissed up :'( STUPID CAREERS PROJECTS DON&quot;T HELP EITHER! \n",
      "Negative Score: 0.9838\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_negative = sampled_data.nlargest(5, 'Negative')\n",
    "\n",
    "# Mostrar los 5 tweets más negativos\n",
    "print(\"================================\")\n",
    "print(\"== Top 5 tweets más negativos ==\")\n",
    "print(\"================================\\n\")\n",
    "for index, row in top_negative.iterrows():\n",
    "    text = row['text']\n",
    "    negative_score = row['Negative']\n",
    "    print(f\"Tweet: {text}\")\n",
    "    print(f\"Negative Score: {negative_score}\")\n",
    "    print(\"\\n------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los 5 tweets con mayor probabilidad de ser neutros, imprimiendo el texto del tweet y sus probabilidades de ser positivo, negativo o neutral. Comprobamos que los tweets con mayor probabilidad de ser neutros, efectivamente lo sean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "=== Top 5 tweets más neutros ===\n",
      "================================\n",
      "\n",
      "Tweet: pssst: Rebecca Taylor footwear sale coming: http://www.thesavvy.com/ May 27th, 2009, 12:00 PM EST (Noon) - May 30th 12:00 AM EST \n",
      "Neutral Score: 0.9507\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: This is a status update to twitter from ICE  Timestamp: Mon Jun 15 11:02:44 CEST 2009\n",
      "Neutral Score: 0.9465\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: This is a status update to twitter from ICE  Timestamp: Sun May 10 10:57:44 CEST 2009\n",
      "Neutral Score: 0.9464\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: This is a status update to twitter from ICE  Timestamp: Mon Jun 15 14:02:34 CEST 2009\n",
      "Neutral Score: 0.9463\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: @amyomy : How long have ya been doing yoga? \n",
      "Neutral Score: 0.9416\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_neutral = sampled_data.nlargest(5, 'Neutral')\n",
    "\n",
    "# Mostrar los 5 tweets más neutros\n",
    "print(\"================================\")\n",
    "print(\"=== Top 5 tweets más neutros ===\")\n",
    "print(\"================================\\n\")\n",
    "for index, row in top_neutral.iterrows():\n",
    "    text = row['text']\n",
    "    neutral_score = row['Neutral']\n",
    "    print(f\"Tweet: {text}\")\n",
    "    print(f\"Neutral Score: {neutral_score}\")\n",
    "    print(\"\\n------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente obtenemos la cantidad de oraciones que componen cada tweet. Para esto, definimos una función llamada `count_sentences` que se encarga de contar el número de oraciones en un texto dado. Esta función utiliza la librería `nltk` y la función `sent_tokenize` para dividir el texto en oraciones. La función `len` se utiliza para contar el número de oraciones en el texto. Es importante mencionar que consideramos como oración a cualquier secuencia de caracteres que termina con un punto.\n",
    "\n",
    "Una vez obtenido el número de oraciones en cada tweet, almacenamos los resultados en una nueva columna llamada 'sentences'. Posteriormente, imprimimos los 5 tweets con mayor número de oraciones, junto con el número de oraciones en cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "\n",
    "# Función para contar las oraciones en un texto y agregarlo como columna 'sentences'\n",
    "def count_sentences(text):\n",
    "    sentences = text.split('.')  # Dividir el texto por puntos\n",
    "    # Eliminar elementos vacíos resultantes de la división\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    return len(sentences)\n",
    "\n",
    "# Aplicar la función a cada fila del DataFrame y agregar la columna 'sentences'\n",
    "sampled_data['sentences'] = sampled_data['text'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "=== Top 5 tweets con más oraciones ===\n",
      "======================================\n",
      "\n",
      "Tweet: Heyy.thnxx.or.inviting.me.to.ur.party.rob.ill.be.down.there.on.june.24th.ill.miss.u.when.u.go.to.italy....   &lt;333333333 txt.me.hon!!! \n",
      "Sentences: 27\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: bob. bob. bob. bob. bob. hair. bob. bob. bob. aaaaaahhh 8O. translation: i cut my hair REALLY short. kinda like it though... \n",
      "Sentences: 12\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: inspired... ahhh.. i love that feeling.. i.n.s.p.i.r.e.d \n",
      "Sentences: 11\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: coffee... guitar lesson... food... interview... food... open mic... food... open mic... food... sleep  Alright Monday, let's do this!\n",
      "Sentences: 10\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Tweet: Laundry. Dishes. Deck cleaning. Virtuality. Sonic Boom. Propane. Beers. BBQ. Boozin. Join me \n",
      "Sentences: 10\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_sentences = sampled_data.nlargest(5, 'sentences')[['text', 'sentences']]\n",
    "\n",
    "# Mostrar los 5 tweets con más oraciones\n",
    "print(\"======================================\")\n",
    "print(\"=== Top 5 tweets con más oraciones ===\")\n",
    "print(\"======================================\\n\")\n",
    "for index, row in top_sentences.iterrows():\n",
    "    text = row['text']\n",
    "    sentences = row['sentences']\n",
    "    print(f\"Tweet: {text}\")\n",
    "    print(f\"Sentences: {sentences}\")\n",
    "    print(\"\\n------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, guardamos el dataset con los resultados obtenidos en un nuevo archivo CSV llamado 'tweets_sentiment.csv' y utilizamos la función `head()` para ver el formato del nuevo dataset, observando los primeros 5 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy fathers day to all the dads out there......</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG noooo leah  u put that pic of us singing '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Bliezy Why don't you like Holland? I'm sure i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3744</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.3524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss my honey..  http://myloc.me/4zQb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.4403</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Am sending good thoughts to my friend Carmi. H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  Positive  \\\n",
       "0  happy fathers day to all the dads out there......       0    0.9435   \n",
       "1  OMG noooo leah  u put that pic of us singing '...       0    0.0850   \n",
       "2  @Bliezy Why don't you like Holland? I'm sure i...       0    0.3744   \n",
       "3              Miss my honey..  http://myloc.me/4zQb       0    0.0938   \n",
       "4  Am sending good thoughts to my friend Carmi. H...       0    0.7920   \n",
       "\n",
       "   Negative  Neutral  sentences  \n",
       "0    0.0102   0.0462          2  \n",
       "1    0.4198   0.4952          1  \n",
       "2    0.2732   0.3524          1  \n",
       "3    0.4659   0.4403          3  \n",
       "4    0.0211   0.1869          2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame actualizado con la nueva columna\n",
    "sampled_data.to_csv('tweets_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
