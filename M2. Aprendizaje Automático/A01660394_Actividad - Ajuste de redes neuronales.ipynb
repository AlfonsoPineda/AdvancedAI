{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad: Ajuste de redes neuronales\n",
    "\n",
    "> Alfonso Pineda Cedillo | A01660394\n",
    "\n",
    "**Fecha de entrega:** 8 de Septiembre de 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "**Instrucciones:** \n",
    "\n",
    "El conjunto de datos de criminalidad de Estados Unidos publicado en el año 1993 consiste de 51 registros para los que se tienen las siguientes variables:\n",
    "\n",
    "-   `VR`: crímenes violentos por cada 100,000 habitantes\n",
    "-   `MR`: asesinatos por cada 100,000 habitantes\n",
    "-   `M`: porcentaje de áreas metropolitanas\n",
    "-   `W`: porcentaje de gente blanca\n",
    "-   `H`: porcentaje de personas con preparatoria terminada\n",
    "-   `P`: porcentaje con ingresos por debajo del nivel de pobreza\n",
    "-   `S`: porcentaje con ingresos por debajo del nivel de pobreza\n",
    "\n",
    "Para este conjunto de datos:\n",
    "\n",
    "1. Evalúa con validación cruzada un modelo pereceptrón multicapa para las variables que se te asignaron para este ejercicio.\n",
    "2. Agrega al conjunto de datos columnas que representen los cuadrados de las variables predictoras (por ejemplo, $M^2$, $W^2$), así como los productos entre pares de variables (por ejemplo, $P \\times S$, $M \\times W$). Evalúa un modelo perceptrón multicapa para este nuevo conjunto de datos.\n",
    "3. Viendo los resultados de regresión, desarrolla una conclusión sobre los siguientes puntos:\n",
    "\n",
    "    A. ¿Consideras que el modelo perceptrón multicapa es efectivo para modelar los datos del problema? ¿Por qué?\n",
    "\n",
    "    B. ¿Qué modelo es mejor para los datos de criminalidad, el lineal o el perceptrón multicapa? ¿Por qué?\n",
    "\n",
    "\n",
    "**Último número de matrícula:** 4\n",
    "\n",
    "> **Variables a utilizar:**  Variable dependiente `MR`, variables independientes: `M`, `W`, `H`, y `P`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución Ejercicio 1\n",
    "Importamos las librerías necesarias para el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el Dataset a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('crime_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la variable de respuesta y las variables predictoras correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['M', 'W', 'H', 'P']]\n",
    "y = data['MR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 1:** Evaluamos con validación cruzada un modelo pereceptrón multicapa para las variables asignadas para este ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos  un modelo de Perceptrón Multicapa (MLPRegressor) con dos capas ocultas, cada una con 100 neuronas, utilizando la configuración `hidden_layer_sizes=(100, 100)`. Este modelo se entrena con todas las observaciones del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con todas las observaciones (dos capas de 100 neuronas)\n",
    "clf = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteiromente, se evalúa el modelo con validación cruzada utilizando el método `cross_val_score` de la librería `sklearn.model_selection`. Esto implica predecir los valores de la variable objetivo (`MR`) y calcular métricas de regresión para evaluar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el modelo (dos capas de 100 neuronas)\n",
    "y_pred = cross_val_predict(MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definimos los rangos para el número de capas ocultas (`num_layers`) y el número de neuronas en cada capa (`num_neurons`). Luego, se crea una lista `layers` que contiene todas las combinaciones posibles de capas y neuronas a probar.\n",
    "\n",
    "Utilizamos `GridSearchCV` para encontrar la mejor configuración de capas y neuronas utilizando validación cruzada con 5 divisiones (`cv=5`). El objetivo es optimizar el rendimiento del modelo encontrando la configuración que minimiza el error de regresión.\n",
    "\n",
    "Por último, imprimimos el mejor estimador encontrado por `GridSearchCV`, que representa la configuración óptima de capas y neuronas para el modelo de Perceptrón Multicapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor estimador encontrado:\n",
      "MLPRegressor(hidden_layer_sizes=[70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70,\n",
      "                                 70, 70, 70, 70],\n",
      "             max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "# Número óptimo de capas y neuronas\n",
    "num_layers = np.arange(1, 20, 5)\n",
    "num_neurons = np.arange(10, 110, 20)\n",
    "layers = []\n",
    "for l in num_layers:\n",
    "    for n in num_neurons:\n",
    "        layers.append(l * [n])\n",
    "\n",
    "# Usamos GridSearchCV para encontrar la mejor configuración de capas y neuronas\n",
    "clf = GridSearchCV(MLPRegressor(max_iter=10000), {'hidden_layer_sizes': layers}, cv=5)\n",
    "clf.fit(X, y)\n",
    "print(\"Mejor estimador encontrado:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos `cross_val_predict` nuevamente para evaluar el modelo con la configuración óptima encontrada en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el modelo encontrando el número óptimo de capas y neuronas\n",
    "clf = GridSearchCV(MLPRegressor(max_iter=10000), {'hidden_layer_sizes': layers}, cv=5)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, obtenemos las métricas de regresión para evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrado Medio (MSE): 85.06261472594268\n",
      "Error Absoluto Medio (MAE): 4.075668724690002\n",
      "Coeficiente de Determinación (R^2): 0.24465428251132648\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el Error Cuadrado Medio (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Error Cuadrado Medio (MSE):\", mse)\n",
    "\n",
    "# Calculamos el Error Absoluto Medio (MAE)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "print(\"Error Absoluto Medio (MAE):\", mae)\n",
    "\n",
    "# Calculamos el Coeficiente de Determinación (R^2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(\"Coeficiente de Determinación (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Agregamos al conjunto de datos columnas que representen los cuadrados de las variables predictoras, así como los productos entre pares de variables.. Evaluamos un modelo perceptrón multicapa para este nuevo conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['M2'] = data['M'] ** 2\n",
    "data['W2'] = data['W'] ** 2\n",
    "data['H2'] = data['H'] ** 2\n",
    "data['P2'] = data['P'] ** 2\n",
    "\n",
    "data['MxW'] = data['M'] * data['W']\n",
    "data['MxH'] = data['M'] * data['H']\n",
    "data['MxP'] = data['M'] * data['P']\n",
    "data['WxH'] = data['W'] * data['H']\n",
    "data['WxP'] = data['W'] * data['P']\n",
    "data['HxP'] = data['H'] * data['P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las variables predictoras actualizadas y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_updated = data[['M', 'W', 'H', 'P', 'M2', 'W2', 'H2', 'P2', 'MxW', 'MxH', 'MxP', 'WxH', 'WxP', 'HxP']]\n",
    "y_updated = data['MR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos  un modelo de Perceptrón Multicapa (MLPRegressor) con dos capas ocultas, cada una con 100 neuronas, utilizando la configuración `hidden_layer_sizes=(100, 100)`. Este modelo se entrena con todas las observaciones del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000)\n",
    "clf.fit(X_updated, y_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteiromente, se evalúa el modelo con validación cruzada utilizando el método `cross_val_score` de la librería `sklearn.model_selection`. Esto implica predecir los valores de la variable objetivo (`MR`) y calcular métricas de regresión para evaluar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_updated = cross_val_predict(MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=10000), X_updated, y_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, obtenemos las métricas de regresión para evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrado Medio (MSE) con variables adicionales: 72433.3941178236\n",
      "Error Absoluto Medio (MAE) con variables adicionales: 131.323474661441\n",
      "Coeficiente de Determinación (R^2) con variables adicionales: -642.1997679161514\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el Error Cuadrado Medio (MSE)\n",
    "mse_updated = mean_squared_error(y_updated, y_pred_updated)\n",
    "print(\"Error Cuadrado Medio (MSE) con variables adicionales:\", mse_updated)\n",
    "\n",
    "# Calculamos el Error Absoluto Medio (MAE)\n",
    "mae_updated = mean_absolute_error(y_updated, y_pred_updated)\n",
    "print(\"Error Absoluto Medio (MAE) con variables adicionales:\", mae_updated)\n",
    "\n",
    "# Calculamos el Coeficiente de Determinación (R^2)\n",
    "r2_updated = r2_score(y_updated, y_pred_updated)\n",
    "print(\"Coeficiente de Determinación (R^2) con variables adicionales:\", r2_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Ejercicio 1\n",
    "\n",
    "**A. ¿Consideras que el modelo perceptrón multicapa es efectivo para modelar los datos del problema? ¿Por qué?**\n",
    "\n",
    "El modelo de perceptrón multicapa sin variables adicionales tiene un $R^2$ de 0.245, lo que significa que solo explica el 24.5% de la varianza en los datos. Esto indica que el modelo no es muy efectivo para modelar la relación entre las variables predictoras y la variable objetivo (crímenes violentos por cada 100,000 habitantes). Además, el MAE de 4.08 es relativamente alto, lo que indica que el modelo tiene un error promedio significativo en sus predicciones.\n",
    "\n",
    "Por otro lado, el modelo de perceptrón multicapa con variables adicionales tiene un rendimiento aún peor, con un MAE y MSE muy altos. Esto sugiere que la inclusión de variables adicionales (cuadrados y productos entre variables) ha empeorado el rendimiento del modelo, lo que indica un posible problema de sobreajuste.\n",
    "\n",
    "**B. ¿Qué modelo es mejor para los datos de criminalidad, el lineal o el perceptrón multicapa? ¿Por qué?**\n",
    "\n",
    "Tomando en cuenta que el modelo lineal obtuvo los siguientes resultasdos:\n",
    "\n",
    "> Error Cuadrado Medio (MSE): 37.37  \n",
    "Error Absoluto Medio (MAE): 3.35  \n",
    "Coeficiente de Determinación ($R^2$): 0.668\n",
    "\n",
    "Podemos conluir que el modelo lineal es claramente mejor para los datos de criminalidad en este caso. Hay varias razones para esto:\n",
    "\n",
    "- **Mejor rendimiento en las métricas:** El modelo lineal tiene un R^2 mucho más alto, lo que significa que explica una mayor proporción de la variabilidad en los datos. Además, el MSE y MAE son significativamente más bajos en el modelo lineal, lo que indica que las predicciones del modelo lineal son más precisas.\n",
    "- **Simplicidad:** El modelo lineal es más simple e interpretable que el perceptrón multicapa. No incluye términos cuadráticos o productos entre variables, lo que hace que sea más fácil entender cómo cada variable predictora afecta a la variable objetivo.\n",
    "- **Menos riesgo de sobreajuste:** El modelo lineal tiene menos riesgo de sobreajuste y generaliza mejor a datos no vistos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 2\n",
    "\n",
    "**Instrucciones:** \n",
    "\n",
    "En este ejercicio trabajarás con datos que vienen de un experimento en el que se midió actividad muscular con la técnica de la Electromiografía en el brazo derecho de varios participantes cuando éstos realizaban un movimiento con la mano entre siete posible (Flexionar hacia arriba, Flexionar hacia abajo, Cerrar la mano, Estirar la mano, Abrir la mano, Coger un objeto, No moverse). Al igual que en el ejercicio anterior, los datos se cargan con la función `loadtxt` de numpy. A su vez, la primera columna corresponde a la clase (1, 2, 3, 4, 5, 6, y 7), la segunda columna se ignora, y el resto de las columnas indican las variables que se calcularon de la respuesta muscular. El archivo de datos con el que trabajarás depende de tu matrícula.\n",
    "\n",
    "Para este conjunto de datos:\n",
    "\n",
    "1. Evalúa un modelo perceptrón multicapa con validación cruzada utilizando al menos 5 capas de 20 neuronas.\n",
    "\n",
    "2. Evalúa un modelo perceptrón multicapa con validación cruzada, pero encontrando el número óptimo de capas y neuronas de la red.\n",
    "\n",
    "3. Prepara el modelo perceptrón multicapa:\n",
    "  \n",
    "      A. Opten los hiperparámetros óptimos de capas y neuronas de la red.\n",
    "  \n",
    "      B. Con los hiperparámetros óptimos, ajusta el modelo con todos los datos.\n",
    "  \n",
    "4. Contesta lo siguiente:\n",
    "\n",
    "      A. ¿Observas alguna mejora importante al optimizar el tamaño de la red? ¿Es el resultado que esperabas? Argumenta tu respuesta.\n",
    "\n",
    "      B. ¿Qué inconvenientes hay al encontrar el tamaño óptimo de la red? ¿Por qué?\n",
    "\n",
    "**Penúltimo número de matrícula:** 9\n",
    "\n",
    "> **Conjunto de datos a utilizar:** `M_5.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución Ejercicio 2\n",
    "Importamos las librerías necesarias para el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el Dataset a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('M_5.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos las características de la clase (`y`) y las etiquetas (`X`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]  # Ignorar la segunda columna (se ignora la primera columna también ya que es la clase)\n",
    "y = data[:, 0]   # La primera columna es la clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 1:** Evaluamos un modelo perceptrón multicapa con validación cruzada utilizando al menos 5 capas de 20 neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este primer paso, definiremos un modelo de MLP con una estructura fija. Utilizaremos 5 capas ocultas, cada una con 20 neuronas. Esto se especificará utilizando el parámetro `hidden_layer_sizes` del clasificador MLPClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20), max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, aplicaremos la validación cruzada para evaluar el rendimiento del modelo en diferentes divisiones de los datos. Utilizaremos la validación cruzada estratificada con 5 pliegues (`StratifiedKFold`) para garantizar que cada clase tenga una representación adecuada en cada pliegue.\n",
    "\n",
    "Durante cada iteración de la validación cruzada, dividiremos los datos en conjuntos de entrenamiento y prueba. Luego, entrenaremos el modelo de MLP en el conjunto de entrenamiento y lo evaluaremos en el conjunto de prueba. Registraremos las predicciones y las etiquetas reales para cada pliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos validación cruzada\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_y_test = []\n",
    "cv_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    # Fase de entrenamiento\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf_cv = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20), max_iter=10000)\n",
    "    clf_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # Fase de prueba\n",
    "    y_pred = clf_cv.predict(X_test)\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al finalizar la validación cruzada, generaremos un informe de clasificación que incluirá métricas de evaluación como la precisión, la recuperación y la puntuación F1 para cada clase y un resumen general del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.90      0.92        90\n",
      "         2.0       0.64      0.68      0.66        90\n",
      "         3.0       0.98      0.96      0.97        90\n",
      "         4.0       0.96      0.97      0.96        90\n",
      "         5.0       0.90      0.90      0.90        90\n",
      "         6.0       0.72      0.69      0.70        90\n",
      "         7.0       0.98      1.00      0.99        89\n",
      "\n",
      "    accuracy                           0.87       629\n",
      "   macro avg       0.87      0.87      0.87       629\n",
      "weighted avg       0.87      0.87      0.87       629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir informe de clasificación\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 2:** Evaluamos un modelo perceptrón multicapa con validación cruzada, pero encontrando el número óptimo de capas y neuronas de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, definimos un rango de posibles números de capas (num_layers) y neuronas (num_neurons). En este caso, estamos explorando desde 1 hasta 19 capas en incrementos de 5, y desde 10 hasta 100 neuronas en incrementos de 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = np.arange(1, 20, 5)\n",
    "num_neurons = np.arange(10, 110, 20)\n",
    "layers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos todas las combinaciones posibles de capas y neuronas utilizando un bucle anidado. Esto nos proporciona una lista de configuraciones de capas ocultas que queremos probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar todas las combinaciones posibles de capas y neuronas\n",
    "for l in num_layers:\n",
    "    for n in num_neurons:\n",
    "        layers.append(l * [n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un clasificador de perceptrón multicapa con búsqueda de cuadrícula (`GridSearchCV`). Este clasificador se ajustará automáticamente con diferentes configuraciones de capas y neuronas y seleccionará la mejor configuración basada en la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(MLPClassifier(max_iter=10000), {'hidden_layer_sizes': layers}, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el clasificador en nuestros datos de entrada (`x`) y etiquetas de salida (`y`) utilizando la función `fit` e imprimimos la mejor configuración encontrada en términos de capas y neuronas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número óptimo de capas y neuronas: [50]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X, y)\n",
    "print(\"Número óptimo de capas y neuronas:\", clf.best_estimator_.hidden_layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, evaluamos el modelo utilizando la validación cruzada y almacenamos las predicciones en `y_pred`. Finalmente, imprimimos un informe de clasificación que muestra métricas de rendimiento como precisión, recuperación y puntuación F1 para cada clase y un resumen general. Esto nos ayuda a evaluar el rendimiento del modelo con la configuración óptima encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.90      0.92        90\n",
      "         2.0       0.63      0.68      0.65        90\n",
      "         3.0       0.96      0.97      0.96        90\n",
      "         4.0       0.97      0.97      0.97        90\n",
      "         5.0       0.90      0.91      0.91        90\n",
      "         6.0       0.72      0.68      0.70        90\n",
      "         7.0       0.98      0.98      0.98        89\n",
      "\n",
      "    accuracy                           0.87       629\n",
      "   macro avg       0.87      0.87      0.87       629\n",
      "weighted avg       0.87      0.87      0.87       629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo encontrando la configuración óptima de capas y neuronas\n",
    "y_pred = cross_val_predict(clf, X, y, cv=5)\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 3:** Preparamos el modelo perceptrón multicapa para producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfonsopineda/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=[50])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=[50])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=[50])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_hidden_layer_sizes = clf.best_params_['hidden_layer_sizes']\n",
    "\n",
    "# Crear y entrenar el modelo con todos los datos\n",
    "clf_final = MLPClassifier(hidden_layer_sizes=best_hidden_layer_sizes)\n",
    "clf_final.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Ejercicio 2\n",
    "\n",
    "**A. ¿Observas alguna mejora importante al optimizar el tamaño de la red? ¿Es el resultado que esperabas? Argumenta tu respuesta.**\n",
    "\n",
    "No, no se observa una mejora importante en los resultados al optimizar el tamaño de la red. Ambos modelos tienen un rendimiento muy similar en términos de precisión y F1-score promedio ponderado, con valores de alrededor del 0.87 en ambas métricas. Esto sugiere que, en este caso particular, aumentar el número de capas y neuronas no condujo a una mejora significativa en el rendimiento del modelo.\n",
    "\n",
    "Esto podría no ser el resultado esperado, ya que normalmente se espera que un modelo más grande (con más capas y neuronas) tenga la capacidad de aprender representaciones más complejas de los datos y, por lo tanto, mejore el rendimiento. Sin embargo, en la práctica, esto puede depender en gran medida de la naturaleza de los datos y la complejidad del problema. En algunos casos, un modelo más pequeño puede ser suficiente para obtener buenos resultados, como parece ser el caso aquí.\n",
    "\n",
    "**B. ¿Qué inconvenientes hay al encontrar el tamaño óptimo de la red? ¿Por qué?**\n",
    "\n",
    "Encontrar el tamaño óptimo de una red neuronal, es decir, el número adecuado de capas y neuronas, puede ser un desafío debido a varios inconvenientes:\n",
    "\n",
    "- **Costo computacional:** Probar todas las combinaciones posibles de hiperparámetros (número de capas y neuronas) puede ser computacionalmente costoso y llevar mucho tiempo, especialmente si se realiza mediante validación cruzada.\n",
    "\n",
    "- **Sobreajuste:** Aumentar el tamaño de la red puede llevar al sobreajuste (overfitting), donde el modelo se adapta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos. Esto puede empeorar el rendimiento en conjuntos de datos no vistos.\n",
    "\n",
    "- **Datos:** Un modelo grande requiere más datos para entrenarse de manera efectiva. Si el conjunto de datos es pequeño, un modelo grande puede tener un rendimiento deficiente debido a la falta de ejemplos de entrenamiento.\n",
    "\n",
    "- **Interpretación:** Un modelo grande puede ser más difícil de interpretar y comprender. Esto puede dificultar la depuración y el ajuste del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
